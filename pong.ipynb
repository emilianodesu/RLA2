{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8332117-8625-4ab1-bae9-b8c5dc9a59f3",
   "metadata": {},
   "source": [
    "# Deep Q-Network on Atari games using Custom CNN\n",
    "\n",
    "This notebook will explore the implementation of a DQN from Stable Baseline3 using a Custom CNN feature extractor on Atari Environment.\n",
    "\n",
    "### What you will learn?\n",
    "* Using Deep Q-Network from Stable Baseline3 Using Custom CNN\n",
    "* Training on Pong Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d94f9d-c908-4d1d-8799-8d799b5d4abf",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646a619-9f73-4b90-abec-3bfd78882c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the necessary packages for Atari environments\n",
    "!pip install gymnasium\n",
    "!pip install gymnasium[atari]\n",
    "!pip install ale-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b19ee-e40c-457d-a4ee-683bc13ce033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary packages for visualization and virtual display\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y cmake\n",
    "# Updating the package list and installing ffmpeg and freeglut3-dev for visualization, xvfb for virtual display\n",
    "!sudo apt-get install -y ffmpeg freeglut3-dev xvfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08c850-c8d8-484c-8f95-98665b0b4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Stable Baselines3 with extra dependencies\n",
    "!pip install \"stable-baselines3[extra]\"\n",
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a9ca9-8a4f-4dda-a561-9871ad68278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # suppress TF INFO/WARN/ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735c1a6-2c5f-41bd-a862-c0db4469eb32",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d3a5a-fd1e-4eb2-bb9a-5efb136348e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import gymnasium as gym\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import base64\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "# Import utility functions for creating Atari environments and stacking frames\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "\n",
    "print(f\"{gym.__version__=}\")\n",
    "print(f\"{stable_baselines3.__version__=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e2fa3-09f3-4c8b-a432-4ccc864174a4",
   "metadata": {},
   "source": [
    "Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c91900-caf0-4984-b64d-1111b2b99fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a fake display for rendering videos in the cloud environment\n",
    "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
    "os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13bb5f-6ba2-4326-8503-4fee70741c82",
   "metadata": {},
   "source": [
    "## Callbacks and directory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2935e4-5f29-4dba-aaf2-513cd9495128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callback class for saving models at regular intervals during training\n",
    "class SaveOnIntervalCallback(BaseCallback):\n",
    "    def __init__(self, save_interval: int, save_path: str, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.save_interval = save_interval\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Save the model every 'save_interval' steps\n",
    "        if self.num_timesteps % self.save_interval == 0:\n",
    "            save_file = os.path.join(self.save_path, f'model_{self.num_timesteps}')\n",
    "            self.model.save(save_file)\n",
    "            if self.verbose > 0:\n",
    "                print(f'Saving model to {save_file}.zip')\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00916b-dd9f-42eb-b887-7212b62f37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directories for storing logs and models\n",
    "log_dir = \"pong/logs\"  # Directory for storing training logs\n",
    "models_dir = \"pong/models/\"  # Directory for storing models\n",
    "\n",
    "# Ensuring the directories exist or creating them\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f582fd-6e3c-4888-9429-c58fa4423ff0",
   "metadata": {},
   "source": [
    "## Define Custom Feature Extractor and Create DQN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a2bf79-2bbe-4283-80c4-4c0aec740a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom CNN feature extractor for processing observations from the environment\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 512):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "        # Define the convolutional layers\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(observation_space.shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute the size of the output tensor after passing through the CNN\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                torch.as_tensor(observation_space.sample()[None]).float()\n",
    "            ).shape[1]\n",
    "\n",
    "        # Define the linear layers that follow the convolutional layers\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        # Process the observations through the CNN and linear layers\n",
    "        return self.linear(self.cnn(observations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4adae7f-a3be-47a3-bf55-92842b7a046b",
   "metadata": {},
   "source": [
    "#### Initial Atari Environment for 'Pong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2f7da-c13a-4e81-b91c-9bc23534dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ale_py\n",
    "env_id = \"PongNoFrameskip-v4\"\n",
    "# Initialize the Atari environment with the specified game and configurations\n",
    "env = make_atari_env(env_id, n_envs=4, seed=0, monitor_dir=log_dir)\n",
    "# Stack 4 consecutive frames together to provide temporal information\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f1560-4c14-4cd8-ad86-d78fad793c1f",
   "metadata": {},
   "source": [
    "#### Initial the DQN model using custon CNN feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2b7e7-e4c3-4824-8589-828c3b2d1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DQN agent with specified parameters\n",
    "model = DQN(\n",
    "    env=env,\n",
    "    policy='CnnPolicy',\n",
    "    verbose=1,\n",
    "    learning_rate=0.0001,\n",
    "    buffer_size=100000,\n",
    "    learning_starts=1000000,\n",
    "    gradient_steps=1,\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_final_eps=0.01,\n",
    "    train_freq=4,\n",
    "    batch_size=32,\n",
    "    ######-----------ADD CUSTOM CNN TO SB3----------------------########\n",
    "    # Uncomment the next line to use the custom CNN feature extractor\n",
    "    policy_kwargs={'features_extractor_class': CustomCNN}\n",
    "    ######------------------------------------------------------########\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eab2d8-7e96-4c72-8739-1b7a8711a773",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cc79e-83a1-44a2-8cae-c3a358bb9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the interval at which models are saved during training\n",
    "save_interval = 100000\n",
    "save_callback = SaveOnIntervalCallback(save_interval, models_dir)\n",
    "\n",
    "# Train the DQN agent\n",
    "model.learn(total_timesteps=10000000, callback=save_callback)\n",
    "\n",
    "# Save the final model after training completes\n",
    "final_model_path = os.path.join(models_dir, f'model_{total_timesteps}')\n",
    "model.save(final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116429cc-c65e-46df-9884-43f20c1bae3c",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501964a-92dc-4946-9b26-2baec9820cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(log_folder: str):\n",
    "    \"\"\"\n",
    "    Plots the training curve from the Monitor log file.\n",
    "    :param log_folder: the save directory of the Monitor logs\n",
    "    \"\"\"\n",
    "    x, y = ts2xy(load_results(log_folder), 'timesteps')\n",
    "    \n",
    "    # Smooth the curve\n",
    "    y_smooth = np.convolve(y, np.ones(100)/100, mode='valid')\n",
    "    x_smooth = x[len(x) - len(y_smooth):]\n",
    "\n",
    "    fig = plt.figure(\"Training Curve\")\n",
    "    plt.plot(x_smooth, y_smooth, label=\"Smoothed Reward\")\n",
    "    plt.plot(x, y, alpha=0.2, label=\"Raw Reward\")\n",
    "    plt.xlabel(\"Number of Timesteps\")\n",
    "    plt.ylabel(\"Rewards\")\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function after training to see the learning curve\n",
    "plot_results(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb687236-3ed0-4725-bf67-620d404aba92",
   "metadata": {},
   "source": [
    "## Video Recording and Display Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf84ad-3d49-40a8-9574-6b1191634fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to record videos of the agent playing and display the videos\n",
    "\n",
    "def show_videos(video_path=\"\", prefix=\"\"):\n",
    "    \"\"\"Displays videos from a specified directory.\"\"\"\n",
    "    html = []\n",
    "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
    "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
    "        html.append(\n",
    "            '''<video alt=\"{0}\" autoplay\n",
    "                      loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{1}\" type=\"video/mp4\" />\n",
    "            </video>'''.format(mp4, video_b64.decode('ascii'))\n",
    "        )\n",
    "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n",
    "\n",
    "\n",
    "def record_video(env_id, model, video_length=500, prefix=\"\", video_folder=\"pong/videos\"):\n",
    "    eval_env = make_atari_env(env_id, n_envs=1, seed=0, vec_env_cls=DummyVecEnv)  # Create a single Atari environment\n",
    "    eval_env = VecFrameStack(eval_env, n_stack=4)  # Stack 4 frames together for temporal information\n",
    "    eval_env = VecVideoRecorder(  # Initialize video recorder\n",
    "        eval_env,\n",
    "        video_folder=video_folder,  # Specify folder to save videos\n",
    "        record_video_trigger=lambda step: step == 0,  # Set trigger to start recording at step 0\n",
    "        video_length=video_length,  # Set video length\n",
    "        name_prefix=prefix,  # Set prefix for video filenames\n",
    "    )\n",
    "    obs = eval_env.reset()  # Reset the environment to get initial observation\n",
    "    for _ in range(video_length):  # Loop through for the specified video length\n",
    "        action, _ = model.predict(obs)  # Predict action based on current observation\n",
    "        obs, _, _, _ = eval_env.step(action)  # Execute action in the environment\n",
    "    eval_env.close()  # Close the environment and video recorder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe18c54-3022-45e9-b946-8071fcc44664",
   "metadata": {},
   "source": [
    "## Record and Display Videos at Different Training Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15827c65-518e-4b60-9c1d-6ad917acdd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for analyzing the trained models\n",
    "\n",
    "# Function to get the identifiers of saved models\n",
    "def get_model_identifiers(models_dir):\n",
    "    files = os.listdir(models_dir)  # Listing files in the models directory\n",
    "    model_files = [f for f in files if f.startswith('model_')]  # Filtering out model files\n",
    "    identifiers = [f.split('_')[1] for f in model_files]  # Extracting identifiers from file names\n",
    "    return identifiers\n",
    "\n",
    "# Function to find key identifiers (earliest, middle, final)\n",
    "def find_key_identifiers(identifiers):\n",
    "    identifiers.sort()  # Sorting identifiers\n",
    "    earliest = identifiers[0]  # Earliest identifier\n",
    "    final = identifiers[-1]  # Final identifier\n",
    "    middle = identifiers[len(identifiers) // 2]  # Middle identifier\n",
    "    return earliest, middle, final\n",
    "\n",
    "# Function to view videos of the models at different training stages\n",
    "def view(models_dir):\n",
    "    identifiers = get_model_identifiers(models_dir)  # Getting model identifiers\n",
    "    print(identifiers)\n",
    "    earliest, middle, final = find_key_identifiers(identifiers)  # Finding key identifiers\n",
    "\n",
    "    # Recording and displaying videos at the beginning, middle, and end of training\n",
    "    for stage, identifier in zip([\"beginning\", \"middle\", \"end\"], [earliest, middle, final]):\n",
    "        model_path = os.path.join(models_dir, f'model_{identifier}')  # Forming the model path\n",
    "        model = DQN.load(model_path)  # Loading the model\n",
    "        record_video(\"PongNoFrameskip-v4\", model, video_length=5000, prefix=f'dqn-pong-{stage}')  # Recording video\n",
    "        show_videos(\"pong/videos/\", prefix=f'dqn-pong-{stage}')  # Showing videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea2d63-c7a8-47e7-9907-4f186983bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the model directory below\n",
    "models_dir=\"pong/models\"\n",
    "view(models_dir)  # Calling the view function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffd8ff-d1ea-42e5-b423-2fa5d75e7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_videos(video_path=\"\", prefix=\"dqn-pong-\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
