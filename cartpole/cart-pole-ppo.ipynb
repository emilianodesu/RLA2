{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilianodesu/RLA2/blob/main/cartpole/cart-pole-ppo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PPO on classic control\n",
        "\n",
        "This notebook will explore the implementation of PPO from Stable Baselines3 on a classic-control environment.\n",
        "\n",
        "### What you will learn?\n",
        "* Using PPO from Stable Baseline3\n",
        "* Training on cart pole environment"
      ],
      "metadata": {
        "id": "ky85O83YJ6h8"
      },
      "id": "ky85O83YJ6h8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Install necessary dependencies."
      ],
      "metadata": {
        "id": "fs63DOtLKHZW"
      },
      "id": "fs63DOtLKHZW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium\n",
        "!pip install \"stable-baselines3[extra]\"\n",
        "!pip install moviepy\n",
        "!sudo apt-get update\n",
        "!apt-get install -y xvfb ffmpeg freeglut3-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "EchSGeAFKKRy"
      },
      "id": "EchSGeAFKKRy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and modules\n",
        "import os\n",
        "import gymnasium as gym\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import base64\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "print(f\"{gym.__version__=}\")\n",
        "print(f\"{stable_baselines3.__version__=}\")"
      ],
      "metadata": {
        "id": "xWX9bLITKKFe"
      },
      "id": "xWX9bLITKKFe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure environment"
      ],
      "metadata": {
        "id": "6mZ8i0hyKQDt"
      },
      "id": "6mZ8i0hyKQDt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a fake display for rendering videos in the cloud environment\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "metadata": {
        "id": "z4FJt-GHKQX-"
      },
      "id": "z4FJt-GHKQX-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks and directory setup"
      ],
      "metadata": {
        "id": "Mi6OgNEnKTLw"
      },
      "id": "Mi6OgNEnKTLw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback for saving the model at regular intervals\n",
        "class SaveOnIntervalCallback(BaseCallback):\n",
        "    def __init__(self, save_interval: int, save_path: str, verbose=1):\n",
        "        super().__init__(verbose)\n",
        "        self.save_interval = save_interval\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.num_timesteps % self.save_interval == 0:\n",
        "            save_file = os.path.join(self.save_path, f'model_{self.num_timesteps}')\n",
        "            self.model.save(save_file)\n",
        "            if self.verbose > 0:\n",
        "                print(f'Saving model to {save_file}.zip')\n",
        "        return True"
      ],
      "metadata": {
        "id": "L1cJo7m0KVxK"
      },
      "id": "L1cJo7m0KVxK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories for storing logs and models\n",
        "log_dir = \"ppo/logs/\"\n",
        "models_dir = \"ppo/models/\"\n",
        "videos_dir = \"ppo/videos/\"\n",
        "\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "os.makedirs(models_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "WKiNVjDgKYBp"
      },
      "id": "WKiNVjDgKYBp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cart pole environment"
      ],
      "metadata": {
        "id": "obBDyB-4Ka9Z"
      },
      "id": "obBDyB-4Ka9Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# ### CHANGE 1: Create the CartPole Environment ###\n",
        "env_id = \"CartPole-v1\"\n",
        "# For PPO, it's common to use multiple environments in parallel\n",
        "env = DummyVecEnv([lambda: Monitor(gym.make(env_id), f\"{log_dir}/{i}\") for i in range(4)])"
      ],
      "metadata": {
        "id": "mfQKTrQtKaxU"
      },
      "id": "mfQKTrQtKaxU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PPO Model"
      ],
      "metadata": {
        "id": "oni2uN9RKeXv"
      },
      "id": "oni2uN9RKeXv"
    },
    {
      "cell_type": "code",
      "source": [
        "policy_kwargs = dict(net_arch=dict(pi=[32, 32], vf=[32, 32]))\n",
        "\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        "    n_steps=256,\n",
        "    batch_size=64,\n",
        "    n_epochs=10,\n",
        "    gamma=0.99,\n",
        "    gae_lambda=0.95,\n",
        "    clip_range=0.2,\n",
        "    ent_coef=0.0,\n",
        "    learning_rate=3e-4,\n",
        "    policy_kwargs=policy_kwargs # Use our custom network\n",
        ")"
      ],
      "metadata": {
        "id": "dhIfSQ8HKdmW"
      },
      "id": "dhIfSQ8HKdmW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "gumlCboBKgwU"
      },
      "id": "gumlCboBKgwU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the callback for saving models\n",
        "save_interval = 10000\n",
        "save_callback = SaveOnIntervalCallback(save_interval=save_interval, save_path=models_dir)\n",
        "\n",
        "# ### CHANGE 4: Reduce total timesteps ###\n",
        "total_timesteps = 50000\n",
        "\n",
        "# Train the DQN agent\n",
        "model.learn(total_timesteps=total_timesteps, callback=save_callback)\n",
        "\n",
        "# Save the final trained model\n",
        "final_model_path = os.path.join(models_dir, f'model_{total_timesteps}')\n",
        "model.save(final_model_path)"
      ],
      "metadata": {
        "id": "Ej8mV8LwKjmw"
      },
      "id": "Ej8mV8LwKjmw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance evaluation"
      ],
      "metadata": {
        "id": "toKRYbkLKj3j"
      },
      "id": "toKRYbkLKj3j"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(log_folder: str):\n",
        "    \"\"\"\n",
        "    Plots the training curve from the Monitor log file.\n",
        "    :param log_folder: the save directory of the Monitor logs\n",
        "    \"\"\"\n",
        "    x, y = ts2xy(load_results(log_folder), 'timesteps')\n",
        "\n",
        "    # Smooth the curve\n",
        "    y_smooth = np.convolve(y, np.ones(100)/100, mode='valid')\n",
        "    x_smooth = x[len(x) - len(y_smooth):]\n",
        "\n",
        "    fig = plt.figure(\"Training Curve\")\n",
        "    plt.plot(x_smooth, y_smooth, label=\"Smoothed Reward\")\n",
        "    plt.plot(x, y, alpha=0.2, label=\"Raw Reward\")\n",
        "    plt.xlabel(\"Number of Timesteps\")\n",
        "    plt.ylabel(\"Rewards\")\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function after training to see the learning curve\n",
        "plot_results(log_dir)"
      ],
      "metadata": {
        "id": "Xx3_HjDIKllB"
      },
      "id": "Xx3_HjDIKllB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Recording and Display Functions"
      ],
      "metadata": {
        "id": "woZg18GtKmTs"
      },
      "id": "woZg18GtKmTs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to record and show videos of the agent playing\n",
        "\n",
        "def show_videos(video_path=\"\", prefix=\"\"):\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(f\"{prefix}*.mp4\"):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            f'''<video alt=\"{mp4.name}\" autoplay loop controls style=\"height: 400px;\">\n",
        "                  <source src=\"data:video/mp4;base64,{video_b64.decode('ascii')}\" type=\"video/mp4\" />\n",
        "             </video>'''\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n",
        "\n",
        "# ### MODIFICATION ###: Updated video folder and env_id\n",
        "def record_video(env_id, model, video_length=500, prefix=\"\", video_folder=\"ppo/videos\"):\n",
        "    os.makedirs(video_folder, exist_ok=True)\n",
        "    eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
        "    eval_env = VecVideoRecorder(\n",
        "        eval_env,\n",
        "        video_folder=video_folder,\n",
        "        record_video_trigger=lambda step: step == 0,\n",
        "        video_length=video_length,\n",
        "        name_prefix=prefix,\n",
        "    )\n",
        "    obs = eval_env.reset()\n",
        "    for _ in range(video_length):\n",
        "        action, _ = model.predict(obs, deterministic=True) # Use deterministic for evaluation\n",
        "        obs, _, _, _ = eval_env.step(action)\n",
        "    eval_env.close()"
      ],
      "metadata": {
        "id": "sgN1G6haKo1A"
      },
      "id": "sgN1G6haKo1A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions for analyzing the trained models\n",
        "\n",
        "# Function to get the identifiers of saved models\n",
        "def get_model_identifiers(models_dir):\n",
        "    files = os.listdir(models_dir)  # Listing files in the models directory\n",
        "    model_files = [f for f in files if f.startswith('model_')]  # Filtering out model files\n",
        "    identifiers = [f.split('_')[1] for f in model_files]  # Extracting identifiers from file names\n",
        "    return identifiers\n",
        "\n",
        "# Function to find key identifiers (earliest, middle, final)\n",
        "def find_key_identifiers(identifiers):\n",
        "    identifiers.sort()  # Sorting identifiers\n",
        "    earliest = identifiers[0]  # Earliest identifier\n",
        "    final = identifiers[-1]  # Final identifier\n",
        "    middle = identifiers[len(identifiers) // 2]  # Middle identifier\n",
        "    return earliest, middle, final\n",
        "\n",
        "# Function to view videos of the models at different training stages\n",
        "def view(models_dir):\n",
        "    identifiers = get_model_identifiers(models_dir)  # Getting model identifiers\n",
        "    print(identifiers)\n",
        "    earliest, middle, final = find_key_identifiers(identifiers)  # Finding key identifiers\n",
        "\n",
        "    # Recording and displaying videos at the beginning, middle, and end of training\n",
        "    for stage, identifier in zip([\"beginning\", \"middle\", \"end\"], [earliest, middle, final]):\n",
        "        model_path = os.path.join(models_dir, f'model_{identifier}')  # Forming the model path\n",
        "        model = DQN.load(model_path)  # Loading the model\n",
        "        record_video(\"CartPole-v1\", model, video_length=5000, prefix=f'ppo-cartpole-{stage}')  # Recording video\n",
        "        show_videos(\"ppo/videos/\", prefix=f'ppo-cartpole-{stage}')  # Showing videos"
      ],
      "metadata": {
        "id": "eTWkQrAAKsBH"
      },
      "id": "eTWkQrAAKsBH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changes the model directory below\n",
        "models_dir=\"ppo/models\"\n",
        "view(models_dir)  # Calling the view function"
      ],
      "metadata": {
        "id": "e9sTwnzWK3LD"
      },
      "id": "e9sTwnzWK3LD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}